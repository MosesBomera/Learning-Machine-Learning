{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter_007.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrsxqKaN7uAi"
      },
      "source": [
        "# Chapter 7. Convolutional Neural Networks Applied to Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22r80QYD73kO"
      },
      "source": [
        "TENSORFLOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdA4CxAG7n-1"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "\n",
        "cifar = keras.datasets.cifar10 \n",
        "(train_images, train_labels), (test_images, test_labels) = cifar.load_data()\n",
        "\n",
        "print(f'Category: {train_labels[90]}')\n",
        "plt.figure(figsize=(1, 1))\n",
        "plt.imshow(train_images[90])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36Ag2-ZS_eWK"
      },
      "source": [
        "## CONVOLUTIONAL NEURAL NETWORK\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.utils import to_categorical \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout, MaxPooling2D\n",
        "import numpy as np \n",
        "import logging \n",
        "tf.get_logger().setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEcDMIZ-cmJf"
      },
      "source": [
        "EPOCHS = 128\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LggkLuMWcpDT"
      },
      "source": [
        "# Load dataset\n",
        "cifar_dataset = keras.datasets.cifar10 \n",
        "(train_images, train_labels), (test_images, test_labels) = cifar_dataset.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlInqqUGczml"
      },
      "source": [
        "# Standardize dataset \n",
        "mean = np.mean(train_images)\n",
        "stddev = np.std(train_images)\n",
        "train_images = (train_images - mean) / stddev\n",
        "test_images = (test_images - mean) / stddev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGOL4CR3c8tz"
      },
      "source": [
        "# Change labels to one-hot.\n",
        "train_labels = to_categorical(train_labels, num_classes=10)\n",
        "test_labels = to_categorical(test_labels, num_classes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXvNWsLxdjDW"
      },
      "source": [
        "# MODEL\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (5,5), strides=(2,2), activation='relu', padding='same', input_shape=(32,32,3),\n",
        "                 kernel_initializer='he_normal', bias_initializer='zeros'))\n",
        "model.add(Conv2D(64, (3,3), strides=(2,2), activation='relu', padding='same', \n",
        "                 kernel_initializer=\"he_normal\", bias_initializer='zeros'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax', \n",
        "                kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eddkKyWRfl8U"
      },
      "source": [
        "history = model.fit(\n",
        "    train_images, train_labels, validation_data=(test_images, test_labels),\n",
        "    epochs=EPOCHS, batch_size=BATCH_SIZE,  verbose=2, shuffle=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjFgy8ihf9KP"
      },
      "source": [
        "# COUNTERING OVERFITTING\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (4,4), activation='relu', padding='same', input_shape=(32,32,3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (2,2), activation='relu', padding='same', strides=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9nbsXh-mOHa"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, validation_data=(test_images, test_labels),\n",
        "                    epochs=EPOCHS, verbose=2, shuffle=True, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-GoamZam5E1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyFCO-R_nJmS"
      },
      "source": [
        "PYTORCH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6v14DzanKd1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from utils import train_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCufF7V9ocKc"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "EPOCHS = 128\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WUYgD2TonDc"
      },
      "source": [
        "# TRAINING DATASET\n",
        "transform = T.Compose([T.ToTensor()])\n",
        "trainset = CIFAR10(root='./pt_data', download=True, train=True, transform=transform)\n",
        "testset = CIFAR10(root='./pt_data', train=False, download=True, transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW8nZrHhtqJc"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXO_v4JjpYBE"
      },
      "source": [
        "# MODEL\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3, 64, 4, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Conv2d(64, 64, 2, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.MaxPool2d(2,2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(32 * 8 * 8, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(64, 10)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ae2tMWprK5m"
      },
      "source": [
        "# Initialize weights with Xavier (Glorot) uniform for all weight layers.\n",
        "for module in model.modules():\n",
        "    if type(module) in {nn.Linear, nn.Conv2d}:\n",
        "        nn.init.xavier_uniform_(module.weight)\n",
        "        nn.init.constant_(module.bias, 0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES6zt87urcXi"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPK9v29Mrm5c"
      },
      "source": [
        "# Train model.\n",
        "train_model(model, device, EPOCHS, BATCH_SIZE, trainset, \n",
        "            testset, optimizer, loss_function, 'acc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nRICgtOuRjM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}