{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter_017_multimodal_learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nz9wcQH6eOT"
      },
      "source": [
        "# CLASSIFICATION WITH MULTIMODAL INPUT DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfZXbV926OHp"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbkH1BFr6z8M",
        "outputId": "9c6e832d-9cde-49dd-de30-baa5166632c6"
      },
      "source": [
        "EPOCHS = 20\n",
        "MAX_WORDS = 8\n",
        "EMBEDDING_WIDTH = 4\n",
        "\n",
        "# Load training and test datasets.\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Standardize the data.\n",
        "mean = np.mean(train_images)\n",
        "stddev = np.std(train_images)\n",
        "train_images = (train_images - mean) / stddev\n",
        "test_images = (test_images - mean) / stddev"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D5ZIifw64YE"
      },
      "source": [
        "# Function to create second modality.\n",
        "def create_text(tokenizer, labels):\n",
        "    text = []\n",
        "    for i, label in enumerate(labels):\n",
        "        if i % 2 == 0:\n",
        "            if label < 5:\n",
        "                text.append('lower half')\n",
        "            else:\n",
        "                text.append('upper half')\n",
        "        else:\n",
        "            if label % 2 == 0:\n",
        "                text.append('even number')\n",
        "            else:\n",
        "                text.append('odd number')\n",
        "    text = tokenizer.texts_to_sequences(text)\n",
        "    text = pad_sequences(text)\n",
        "    return text\n",
        "\n",
        "# Create second modality for training and test set.\n",
        "vocabulary = ['lower', 'upper', 'half', 'even', 'odd', 'number']\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS)\n",
        "tokenizer.fit_on_texts(vocabulary)\n",
        "train_text = create_text(tokenizer, train_labels)\n",
        "test_text = create_text(tokenizer, test_labels)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlLlUWpd7H2X"
      },
      "source": [
        "# Create model with functional API.\n",
        "image_input = Input(shape=(28, 28))\n",
        "text_input = Input(shape=(2, ))\n",
        "\n",
        "# Declare layers.\n",
        "embedding_layer = Embedding(output_dim=EMBEDDING_WIDTH,\n",
        "                            input_dim = MAX_WORDS)\n",
        "lstm_layer = LSTM(8)\n",
        "flatten_layer = Flatten()\n",
        "concat_layer = Concatenate()\n",
        "dense_layer = Dense(25,activation='relu')\n",
        "output_layer = Dense(10, activation='softmax')\n",
        "\n",
        "# Connect layers.\n",
        "embedding_output = embedding_layer(text_input)\n",
        "lstm_output = lstm_layer(embedding_output)\n",
        "flatten_output = flatten_layer(image_input)\n",
        "concat_output = concat_layer([lstm_output, flatten_output])\n",
        "dense_output = dense_layer(concat_output)\n",
        "outputs = output_layer(dense_output)\n",
        "\n",
        "# Build and train model.\n",
        "model = Model([image_input, text_input], outputs)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam', metrics =['accuracy'])\n",
        "model.summary()\n",
        "history = model.fit([train_images, train_text], train_labels,\n",
        "                    validation_data=([test_images, test_text],\n",
        "                                     test_labels), epochs=EPOCHS,\n",
        "                    batch_size=64, verbose=2, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "jrFKpDCv7jOd",
        "outputId": "3dbdab5b-7044-4fb8-d508-80ce8db2a3e5"
      },
      "source": [
        "# Print input modalities and output for one test example.\n",
        "print(test_labels[0])\n",
        "print(tokenizer.sequences_to_texts([test_text[0]]))\n",
        "plt.figure(figsize=(1, 1))\n",
        "plt.imshow(test_images[0], cmap=plt.get_cmap('gray'))\n",
        "plt.show()\n",
        "\n",
        "# Predict test example.\n",
        "y = model.predict([test_images[0:1], np.array(\n",
        "    tokenizer.texts_to_sequences(['upper half']))])[0] #7\n",
        "print('Predictions with correct input:')\n",
        "for i in range(len(y)):\n",
        "    index = y.argmax()\n",
        "    print('Digit: %d,' %index, 'probability: %5.2e' %y[index])\n",
        "    y[index] = 0\n",
        "\n",
        "# Predict same test example but with modified textual description.\n",
        "print('\\nPredictions with incorrect input:')\n",
        "y = model.predict([test_images[0:1], np.array(\n",
        "    tokenizer.texts_to_sequences(['lower half']))])[0] #7\n",
        "for i in range(len(y)):\n",
        "    index = y.argmax()\n",
        "    print('Digit: %d,' %index, 'probability: %5.2e' %y[index])\n",
        "    y[index] = 0"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "['upper half']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions with correct input:\n",
            "Digit: 7, probability: 1.00e+00\n",
            "Digit: 9, probability: 2.76e-08\n",
            "Digit: 2, probability: 4.89e-10\n",
            "Digit: 8, probability: 2.71e-11\n",
            "Digit: 5, probability: 8.72e-12\n",
            "Digit: 3, probability: 3.60e-12\n",
            "Digit: 6, probability: 5.55e-13\n",
            "Digit: 0, probability: 1.46e-14\n",
            "Digit: 4, probability: 1.68e-16\n",
            "Digit: 1, probability: 5.59e-18\n",
            "\n",
            "Predictions with incorrect input:\n",
            "Digit: 7, probability: 9.67e-01\n",
            "Digit: 2, probability: 3.21e-02\n",
            "Digit: 3, probability: 2.79e-04\n",
            "Digit: 0, probability: 1.51e-04\n",
            "Digit: 4, probability: 4.60e-06\n",
            "Digit: 1, probability: 1.01e-08\n",
            "Digit: 9, probability: 2.65e-09\n",
            "Digit: 8, probability: 9.85e-11\n",
            "Digit: 5, probability: 7.87e-11\n",
            "Digit: 6, probability: 2.45e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id8EkmNK8ADK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}